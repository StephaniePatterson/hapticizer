{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import time\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import subprocess\n",
    "from pythonosc.udp_client import SimpleUDPClient\n",
    "import sounddevice as sd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Hapticizer 3000. Enter a number:\n",
      "FRAME LENGTH:  0.01\n",
      "length 929\n",
      "Sending message\n",
      "Sending message\n",
      "Sending message\n",
      "Sending message\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# ADD:\n",
    "# MESSAGE FOR CHANGING PITCH (done)\n",
    "# AUDIO FILE PROCESSING SUPPORT + saving to audio file (done)\n",
    "# INPUT/OUTPUT TIMESTAMP\n",
    "# look at sampling size, make sure it is calculating correctly (yes, it's getting f1)\n",
    "# have the hapticizer the same volume as speaker : NEED TO MAKE TIMEFRAME OF SOUND A LITTLE LONGER!!! (done)\n",
    "# multiple options for how to process speech\n",
    "# ideas: \n",
    "# - quiet mode / crowded room mode with different intensity thresholds\n",
    "# - \n",
    "\n",
    "# Create UDP client to send pitch to chuck code\n",
    "client = SimpleUDPClient(\"127.0.0.1\", 6449)\n",
    "hmin = 100\n",
    "hmax = 300\n",
    "vmin = 80\n",
    "vmax = 400\n",
    "fs = 44100\n",
    "\n",
    "\n",
    "print(\"Welcome to Hapticizer 3000. Enter a number:\")\n",
    "choice = input(\"(1) Hapticize an audio file \\n(2) Hapticize real-time audio\\n\")\n",
    "\n",
    "if choice == \"1\":\n",
    "    filename = input(\"What file would you like to hapticize? \")\n",
    "    sound = parselmouth.Sound(filename)\n",
    "    pitch = sound.to_pitch()\n",
    "    intensity = sound.to_intensity()\n",
    "    intensity_values = intensity.values[0]\n",
    "    timestep = pitch.dt\n",
    "    print(\"FRAME LENGTH: \", pitch.dt)\n",
    "    print(\"length\", len(pitch.selected_array[\"frequency\"]))\n",
    "    input(\"Start the hapticizer and then press enter to start.\")\n",
    "    #Frame length is 0.01 sec\n",
    "    #To make chunk size the same as real-time, we need to get avg pitch of every 500 samples\n",
    "    pitch_total = 0.0\n",
    "    for frame in range(len(pitch.selected_array[\"frequency\"])):\n",
    "        curpitch = pitch.selected_array[\"frequency\"][frame]\n",
    "        if frame % 20 != 0:\n",
    "            pitch_total += curpitch\n",
    "        else:\n",
    "            curpitch = pitch_total / 20\n",
    "            curintensity = 0.0\n",
    "            if frame < len(intensity_values):\n",
    "                curintensity = intensity_values[frame]\n",
    "            if curintensity > 20 and curpitch > 80 and curpitch < 1000:\n",
    "                    \n",
    "                normalized_pitch = hmin + ((curpitch - vmin) / (vmax - vmin)) * hmax\n",
    "                            # Normalize intensity to Chuck's gain range, 0-1\n",
    "                            # Guesstimating intensity range to be like 30-100 dB\n",
    "                normalized_intensity = (curintensity - 30) / (100 - 30)\n",
    "                print(\"Sending message\")\n",
    "                client.send_message(\"/pitch\", float(normalized_pitch))\n",
    "                if curintensity < 50:\n",
    "                    client.send_message(\"/loudness\", 0.1)\n",
    "                elif curintensity > 70:\n",
    "                    client.send_message(\"/loudness\", 1.0)\n",
    "                else:\n",
    "                    client.send_message(\"/loudness\", 0.5)\n",
    "            \n",
    "            pitch_total = 0.0\n",
    "            \n",
    "        time.sleep(timestep)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "else:        \n",
    "\n",
    "    def detect_and_send_pitch(audio, sample_rate):\n",
    "        # Convert audio to a Parselmouth Sound object\n",
    "        sound = parselmouth.Sound(audio, sampling_frequency=sample_rate)\n",
    "        rms = sound.get_rms()\n",
    "        intensity = sound.get_intensity()\n",
    "        print(\"Intensity\", sound.get_intensity())\n",
    "\n",
    "        # Sound intensity threshold: if sound is less than 30 dB, ignore it\n",
    "        # Probably needs to be higher than 30 in practice especially in a noisy environment\n",
    "        if intensity < 30:\n",
    "            return\n",
    "        print(\"detect and send pitch\")\n",
    "        # Extract pitch using Parselmouth\n",
    "        pitch = sound.to_pitch(pitch_floor=120)\n",
    "        print(\"FRAME LENGTH\", pitch.dt)\n",
    "        print(\"whole thing length\", pitch.get_total_duration())\n",
    "        pitch_values = pitch.selected_array['frequency']\n",
    "\n",
    "        total = 0.0\n",
    "\n",
    "        for value in pitch_values:\n",
    "            # Detect pitches in human voice range: 80-300 Hz\n",
    "            total = total + value\n",
    "        \n",
    "        value = total / len(pitch_values)\n",
    "        print(\"VALUE\", value)\n",
    "\n",
    "        vmin = 80\n",
    "        vmax = 400\n",
    "        if value > vmin and value < vmax:\n",
    "            print(value)\n",
    "\n",
    "            # Normalize to haptic range: 100-300 Hz (SUBJECT TO CHANGE)\n",
    "            hmin = 100\n",
    "            hmax = 300\n",
    "            normalized_pitch = hmin + ((value - vmin) / (vmax - vmin)) * hmax\n",
    "\n",
    "            # Normalize intensity to Chuck's gain range, 0-1\n",
    "            # Guesstimating intensity range to be like 30-100 dB\n",
    "            normalized_intensity = (intensity - 30) / (100 - 30)\n",
    "            client.send_message(\"/pitch\", normalized_pitch)\n",
    "            if intensity < 50:\n",
    "                client.send_message(\"/loudness\", 0.1)\n",
    "            elif intensity > 70:\n",
    "                client.send_message(\"/loudness\", 1.0)\n",
    "            else:\n",
    "                client.send_message(\"/loudness\", 0.5)\n",
    "            #time.sleep(0.2)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        print(\"callback\")\n",
    "        if status:\n",
    "            print(status)\n",
    "        mono_audio=np.mean(indata, axis=1)\n",
    "        detect_and_send_pitch(mono_audio, fs)\n",
    "\n",
    "    #Duration will be the length of the chunk used to get the pitch and intensity\n",
    "    #Currently 0.5 seconds\n",
    "    duration = int(fs * 0.5)\n",
    "\n",
    "    with sd.InputStream(channels=1, samplerate=fs, blocksize=duration, callback=audio_callback):\n",
    "        print(\"Listening...\")\n",
    "        while True:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "    # General function for analyzing sound\n",
    "    def analyze_sound(sound):\n",
    "        analysis = {\"pitch\":[], \"intensity\":[], \"avgPitch\":0, \"avgIntensity\":0, \"times\":[]}\n",
    "        pitch = sound.to_pitch()\n",
    "        analysis[\"pitch\"] = pitch.values[0]\n",
    "        analysis[\"avgPitch\"] = pitch.selected_array['frequency']\n",
    "\n",
    "        intensity = sound.to_intensity()\n",
    "        analysis[\"times\"] = intensity.xs()\n",
    "        analysis[\"intensity\"] = intensity.values[0]\n",
    "        analysis[\"avgIntensity\"] = intensity.get_average()\n",
    "        print(analysis[\"avgIntensity\"])\n",
    "        return analysis\n",
    "\n",
    "    # Previous attempt at sending sound (slow and finicky)\n",
    "\n",
    "    def send_intensity_to_chuck(chuck_instance, times, intensity_values, output_wav):\n",
    "        \n",
    "        new_intensity = []\n",
    "\n",
    "        #python library that detects voice; when voice off, play the vibration for the previous utterance (maximum time frame?)\n",
    "        \n",
    "        #approach that records some and then processes it with delay\n",
    "        r = sr.Recognizer()\n",
    "        r.pause_threshold = 0.8 # this is the default; can be changed\n",
    "        with sr.Microphone() as source:\n",
    "            audio = r.listen(source)\n",
    "            wav_data = audio.get_wav_data()\n",
    "            cur_sound = parselmouth.Sound(wav_data, audio.sample_rate)\n",
    "            analysis = analyze_sound(cur_sound)\n",
    "\n",
    "\n",
    "        # can it be even more real time.... ponder \n",
    "        for time_step, intensity in zip(analysis[\"times\"], analysis[\"intensity\"]):\n",
    "            #normalize intensity and pitch\n",
    "            s.setGain(intensity)\n",
    "\n",
    "        subprocess.run([\"chuck\", \"hapticize.ck\"])\n",
    "        chuck_instance.run(\"\"\"\n",
    "        SinOsc s => Gain g => dac; // Sine oscillator\n",
    "        s => WvOut w => blackhole;\n",
    "\n",
    "        \"{output}\" => w.wavFilename;\n",
    "\n",
    "        200 => s.freq;   // Base frequency\n",
    "        0.1::second => dur d; // Time step\n",
    "\n",
    "        fun void updateGain(float newGain) {\n",
    "            newGain => s.gain; // Update the gain based on intensity\n",
    "        }\n",
    "\n",
    "        while (true) {\n",
    "            1::second => now; // Keep the ChucK VM running\n",
    "        }\n",
    "        \"\"\")\n",
    "\n",
    "        # Send the intensity data to ChucK\n",
    "        for time_step, intensity in zip(times, intensity_values):\n",
    "            chuck_instance.call(\"updateGain\", [float(intensity)])\n",
    "            time.sleep(time_step)\n",
    "\n",
    "    # output = open(\"output.wav\", \"wb\")\n",
    "    # send_intensity_to_chuck(chuck_instance, times, values, output)\n",
    "\n",
    "    #if [acoustic property] > number, add a haptic vibration for it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
